<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OpenNerf: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views">
  <meta name="keywords" content="OpenNeRF, open-vocabulary segmentation, 3D segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OpenNerf: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OpenNeRF</h1>
          <h1 class="title is-3 publication-title">OpenSet 3D Neural Scene Segmentation with Pixel-wise Features and Rendered Novel Views</h1>
          <h1 class="title is-5 publication-title">ICLR 2024</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://francisengelmann.github.io/">Francis Engelmann</a><sup>1,2</sup>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.de/citations?user=bERItx8AAAAJ">Fabian Manhardt</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://m-niemeyer.github.io">Michael Niemeyer</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ml3laqEAAAAJ">Keisuke Tateno</a><sup>2</sup></span>
            <span class="author-block">
            <span class="author-block">
              <a href="https://people.inf.ethz.ch/pomarc/">Marc Pollefeys</a><sup>1,3</sup>
            </span>
            <span class="author-block">
              <a href="https://federicotombari.github.io/">Federico Tombari</a><sup>2,4</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH Zurich </span>
            <span class="author-block"><sup>2</sup>Google</span>
            <span class="author-block"><sup>3</sup>Microsoft</span>
	    <span class="author-block"><sup>4</sup>TU Munich<sup>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.03650"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              
              <!-- Code Link. -->
              <span class="link-block">
                  <a href="https://github.com/opennerf/opennerf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
              </span>
              
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=SgjAojPKb3"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>üìï OpenReview</span>
                </a>
              </span>

              <!-- NerfStudio Link. -->
              <span class="link-block">
                <a href="https://docs.nerf.studio/nerfology/methods/opennerf.html" class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
                  <span>üöú NerfStudio</span>
                </a>
            </span>

            <span class="link-block">
              <a href="http://129.132.245.145/" class="external-link button is-normal is-rounded is-dark">
                <!-- <span class="icon"><i class="fab fa-github"></i></span> -->
                <span>‚ô•Ô∏è Demo</span>
              </a>
          </span>

            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container is-max-desktop">
      <img src="./static/images/teaser.png" class="teaser-fig" alt="teaser-fig." />
      <h2 class="subtitle has-text-centered">
        Open-vocabulary 3D semantic segmentation on point clouds.
        Compared to LERF,
        the segmentation masks of OpenNeRF are more accurate and better localized, while achieving more fine-grained classification than
        OpenScene. We show zero-shot results on the Replica dataset.
      </h2>
    </div>
  </div>
</section>


<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large visual-language models (VLMs), like CLIP, enable open-set image segmentation to segment arbitrary concepts
            from an image in a zero-shot manner. This goes beyond the traditional closed-set assumption, i.e., where models
            can only segment classes from a pre-defined training set. More recently, first works on open-set segmentation in
            3D scenes have appeared in the literature. These methods are heavily influenced by closed-set 3D convolutional
            approaches that process point clouds or polygon meshes. However, these 3D scene representations do not align well
            with the image-based nature of the visual-language models. Indeed, point cloud and 3D meshes typically have a lower
            resolution than images and the reconstructed 3D scene geometry might not project well to the underlying 2D image
            sequences used to compute pixel-aligned CLIP features. To address these challenges, we propose OpenNeRF which naturally
            operates on posed images and directly encodes the VLM features within the NeRF. This is similar in spirit to LERF,
            however our work shows that using pixel-wise VLM features (instead of global CLIP features) results in an overall
            less complex architecture without the need for additional DINO regularization. Our OpenNeRF further leverages NeRF's
            ability to render novel views and extract open-set VLM features from areas that are not well observed in the initial
            posed images. For 3D point cloud segmentation on Replica, OpenNeRF outperforms recent open-vocabulary methods
            such as LERF and OpenScene by at least +4.9 mIoU.
          </p>
        </div>
      </div>
    </div>

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Zero-Shot 3D Semantic Segmentation</h2>
    Replica - Office 0 <br>
    <a href="static/visualizations/office0/index.html"><img src="static/visualizations/final_office0_.gif"></a><br>
    Replica - Office 1 <br>
    <a href="static/visualizations/office1/index.html"><img src="static/visualizations/final_office1_.gif"></a><br>
    Replica - Office 2 <br>
    <a href="static/visualizations/office2/index.html"><img src="static/visualizations/final_office2_.gif"></a><br>
    Replica - Office 3 <br>
    <a href="static/visualizations/office3/index.html"><img src="static/visualizations/final_office3_.gif"></a><br>
    Replica - Room 0 <br>
    <a href="static/visualizations/room0/index.html"><img src="static/visualizations/final_room0_.gif"></a><br>
    Replica - Room 1 <br>
    <a href="static/visualizations/room1/index.html"><img src="static/visualizations/final_room1_.gif"></a><br>
    Replica - Room 2 <br>
    <a href="static/visualizations/room2/index.html"><img src="static/visualizations/final_room2_.gif"></a><br>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Open-Vocabulary 3D Search</h2>
    <img src="static/images/fishplate.gif" /><br>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@inproceedings{engelmann2024opennerf,
   title={{OpenNerf: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views}},
   author={Engelmann, Francis and Manhardt, Fabian and Niemeyer, Michael and Tateno, Keisuke and Pollefeys, Marc and Tombari, Federico},
   booktitle={International Conference on Learning Representations (ICLR)},
   year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <!-- <div class="column is-8"> -->
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It borrows the source code of <a
              href="https://nerfies.github.io/">this website</a>,
              We sincerely thank <a
              href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</footer>

</body>
</html>
